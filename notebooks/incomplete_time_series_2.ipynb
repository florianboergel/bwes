{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of incomplete time series - Part 2\n",
    "\n",
    "This part will focus on the analysis of irregular time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Reconstruction of cyanobacterial blooms\n",
    "\n",
    "We read in a time series of a biomarker indicating past cyanobacterial blooms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cyano_rec <- read.csv(\"../Data/Biomarker_Faeroe.csv\",dec=',',header=TRUE,sep=\"\\t\")\n",
    "head(Cyano_rec)\n",
    "plot(Cyano_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there is a positive trend: We have more cyanobacteria today. But can we prove it?\n",
    "\n",
    "Let us first try a simple linear model. This assumes that the data show a linear rise plus a random error at each data point. The random errors are independent and normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear model\n",
    "my_lm = lm(formula = Cya~Age,data=Cyano_rec)\n",
    "# print a summary of the model fit\n",
    "summary(my_lm)\n",
    "# plot the data and the fitted model\n",
    "plot(Cyano_rec$Age, Cyano_rec$Cya)\n",
    "lines(Cyano_rec$Age,predict(my_lm,Cyano_rec))\n",
    "# print the uncertainty interval for the slope\n",
    "confint(my_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model finds a significantly positive trend of 0.0059 year$^{-1}$. But is the model suitable for the data? \n",
    "To find that out, we should **always have a look at the residuals**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(resid(my_lm))\n",
    "hist(resid(my_lm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residuals violate both assumptions we made: \n",
    "* They are not independent: we see clustering especially of negative residuals.\n",
    "* They are not normally distributed: We see that their distribution is skewed.\n",
    "So, the model is inappropriate, **it is wrong to use its results**.\n",
    "\n",
    "We can plot the autocorrelation between the residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf(resid(my_lm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that lag-1 and lag-2 autocorrelation are significantly positive. \n",
    "**If we ignore this, the model may dramatically underestimate the uncertainty of the slope!**\n",
    "\n",
    "Next attempt: We assume that the residuals are autocorrelated in time. For irregular time series, we can use the continuous AR-1 autocorrelation and do a generalised least-squares fit:\n",
    "$$E(\\varepsilon_n \\cdot \\varepsilon_{n+1}) = \\sigma^2 \\exp(-r(t_{n+1}-t_n))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"nlme\")\n",
    "# do generalised least-squares fit\n",
    "my_gls = gls(Cya~Age,data=Cyano_rec,correlation = corCAR1(form=~Age))\n",
    "summary(my_gls)\n",
    "# plot the data and the fitted model\n",
    "plot(Cyano_rec$Age, Cyano_rec$Cya)\n",
    "lines(Cyano_rec$Age,predict(my_gls,Cyano_rec))\n",
    "# print the uncertainty interval for the slope\n",
    "confint(my_gls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the new residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three types of residuals:\n",
    "# \"response\"     = the full residuals epsilon_n\n",
    "# \"standardized\" = divided by standard deviation sigma\n",
    "# \"normalized\"   = divided by standard deviation sigma and corrected for assumed autocorrelation\n",
    "my_residuals = resid(my_gls,type=\"normalized\")\n",
    "\n",
    "plot(my_residuals)\n",
    "hist(my_residuals)\n",
    "acf(my_residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a model we could publish if we are interested in a linear trend. \n",
    "\n",
    "But fitting a straight line is not optimal for matching the data. Let's look at the plot again:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data and the fitted model\n",
    "plot(Cyano_rec$Age, Cyano_rec$Cya)\n",
    "lines(Cyano_rec$Age,predict(my_gls,Cyano_rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't it look like there are basically two shifts: A rise in the 1920s to values around 0.7, and then another rise in the 1990s?\n",
    "\n",
    "We can actually find this out by using a \"nonparametric model\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonparametric models\n",
    "\n",
    "In classical regression models, we prescribe the shape of the trend (linear, quadratic, ...) and let the model estimate the coefficients only. \n",
    "\n",
    "In \"nonparametric models\", the model shall also estimate the shape of the response. A good idea is to use \"splines\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splines\n",
    "\n",
    "Splines (=smooth polinomial lines) are a nice way to fit smooth lines through given data.\n",
    "\n",
    "Assume we have some points which we want to fit the data through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = c(0,1,2,3)\n",
    "y_values = c(1,2,4,1)\n",
    "plot(x_values,y_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could of course connect neighbouring points by straight lines, but that would not be smooth.\n",
    "The slope would change abruptly at these \"knots\".\n",
    "\n",
    "An alternative is to define the slope at the knots as well and then to fit a third-order polynomial between every two knots. \n",
    "A third-order polynomial\n",
    "$$ y = ax^3 + bx^2 + cx + d $$\n",
    "has four degrees of freedom, so it is uniquely defined by two y-values and two slopes at each end.\n",
    "\n",
    "the R function __splinefunH()__ returns a function that fits the given knots and slopes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes = c(-1,2,0,-3)\n",
    "my_splinefunction = splinefunH(x=x_values, y=y_values, m=slopes)  # determine spline function\n",
    "x_axis = seq(from=0,to=3,by=0.1)                                  # define an x axis vector\n",
    "my_spline = my_splinefunction(x_axis)                             # apply the function to the x values to obtain y values\n",
    "\n",
    "# now plot the spline as line and the knots as points\n",
    "plot(x_axis,my_spline,type=\"l\")\n",
    "points(x_values,y_values,col=\"red\",pch=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of spline with cubic polynomials between the knots is called \"Hermite spline\". \n",
    "\n",
    "Assume we have some data which are scattered in $x$ and $y$. A non-parametric model will automatically optimise the vertical position of the knot points and the slopes to find the line which fits your data best. \n",
    "\n",
    "Such a model is known as a **Generalised Additive Model (GAM)**. Here you can find a comprehensive book on how these are designed and applied:\n",
    "[Wood, S.N., 2017. Generalized additive models: an introduction with R. Chapman and Hall/CRC. https://www.taylorfrancis.com/books/9781498728348 ]\n",
    "\n",
    "You can use the function **gam()** from the R package **mgcv** to fit such a model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the library\n",
    "library(\"mgcv\")\n",
    "# fit a gam model\n",
    "x_values=seq(1880,2020,by=20)\n",
    "my_gam = gam(Cya~s(Age, bs=\"cr\", k=8), data=Cyano_rec, knots=list(Age=x_values), optimMethod=\"ML\", sp=0)\n",
    "# plot the data\n",
    "plot(Cyano_rec$Age, Cyano_rec$Cya)\n",
    "# plot the model\n",
    "lines(Cyano_rec$Age,predict(my_gam,Cyano_rec))\n",
    "# calculate the knots and plot them\n",
    "y_values = predict(my_gam,data.frame(Age=x_values))\n",
    "points(x_values,y_values,col=\"red\",pch=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters (y_values and slopes) are stored in a parameter vector $\\mathbf{\\beta}$. This was optimised to maximise the likelihood $l(\\mathbf{\\beta})$.\n",
    "\n",
    "$$ \\mathbf{y} = \\beta_0 + s(\\mathbf{x},\\mathbf{\\beta}) + \\mathbf{\\varepsilon} $$\n",
    "$$ \\mathbf{y} = \\beta_0 + \\mathbf{X} \\cdot \\mathbf{\\beta} + \\mathbf{\\varepsilon} $$\n",
    "\n",
    "The smoothness now depends on the number of knots we use. We can, however, ask the fitting function to produce a smoother spline. \n",
    "\n",
    "We want to punish if the second derivative (=curvature) gets too large, that is, we want to keep\n",
    "$$ \\int_{x} (s''(x,\\mathbf{\\beta}))^2 $$\n",
    "small.\n",
    "\n",
    "The smoothing parameter **sp** controls this.  It means that we will fit a restricted likelihood\n",
    "$$ l_{restricted}(\\mathbf{\\beta}) = l(\\mathbf{\\beta}) - sp \\cdot \\mathbf{\\beta} \\cdot \\mathbf{S} \\cdot \\mathbf{\\beta} $$\n",
    "\n",
    "Let's try different values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit three models\n",
    "my_gam1 = gam(Cya~s(Age, bs=\"cr\", k=8), data=Cyano_rec, knots=list(Age=x_values), optimMethod=\"ML\", sp=1)\n",
    "my_gam2 = gam(Cya~s(Age, bs=\"cr\", k=8), data=Cyano_rec, knots=list(Age=x_values), optimMethod=\"ML\", sp=2)\n",
    "my_gam5 = gam(Cya~s(Age, bs=\"cr\", k=8), data=Cyano_rec, knots=list(Age=x_values), optimMethod=\"ML\", sp=5)\n",
    "# plot them all\n",
    "plot(Cyano_rec$Age, Cyano_rec$Cya)\n",
    "lines(Cyano_rec$Age,predict(my_gam,Cyano_rec))\n",
    "lines(Cyano_rec$Age,predict(my_gam1,Cyano_rec),col=\"blue\")\n",
    "lines(Cyano_rec$Age,predict(my_gam2,Cyano_rec),col=\"green\")\n",
    "lines(Cyano_rec$Age,predict(my_gam5,Cyano_rec),col=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the method will choose an appropriate value for sp automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto-select sp\n",
    "my_gam_auto = gam(Cya~s(Age, bs=\"cr\", k=8), data=Cyano_rec, knots=list(Age=x_values), optimMethod=\"ML\")\n",
    "# plot all\n",
    "plot(Cyano_rec$Age, Cyano_rec$Cya)\n",
    "lines(Cyano_rec$Age,predict(my_gam,Cyano_rec))\n",
    "lines(Cyano_rec$Age,predict(my_gam1,Cyano_rec),col=\"blue\")\n",
    "lines(Cyano_rec$Age,predict(my_gam2,Cyano_rec),col=\"green\")\n",
    "lines(Cyano_rec$Age,predict(my_gam5,Cyano_rec),col=\"orange\")\n",
    "lines(Cyano_rec$Age,predict(my_gam_auto,Cyano_rec),col=\"red\")\n",
    "# show chosen value\n",
    "my_gam_auto$sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also want to take temporal autocorrelation of the data into account. Then we need to choose a **Generalised Additive Mixed Model (GAMM)**.\n",
    "\n",
    "The fitting procedure is similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_gamm = gamm(Cya ~ s(Age, bs=\"cr\", k = 8), data=Cyano_rec, \n",
    "               knots=list(Age=x_values), optimMethod=\"ML\", \n",
    "               correlation = corCAR1(form = ~ Age))\n",
    "# print the summary of the gamm\n",
    "summary(my_gamm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model has two components: \n",
    "* **lme** contains the local mixed-effects model\n",
    "* **gam** contains the generalised additive model\n",
    "\n",
    "The actual GAMM is a combination of the two. We can use the **gam** model part as before and plot the estimated trend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(Cyano_rec$Age, Cyano_rec$Cya)\n",
    "lines(Cyano_rec$Age,predict(my_gam_auto,Cyano_rec),col=\"red\")\n",
    "lines(Cyano_rec$Age,predict(my_gamm$gam,Cyano_rec),col=\"violet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **lme** part will tell us about the temporal autocorrelation which was estimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(my_gamm$lme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the residuals for autocorrelation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf(resid(my_gamm$lme,type=\"normalized\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "they don't show a significant autocorrelation any more, so we may say the cAR1 model describes the autocorrelation well enough.\n",
    "\n",
    "The nonparametric fit also gives confidence intervals for the spline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a prediction with standard error\n",
    "my_prediction = predict.gam(my_gamm$gam,se.fit=TRUE)\n",
    "summary(my_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see we have two entries: **fit** and **se.fit**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data and model\n",
    "plot(Cyano_rec$Age, Cyano_rec$Cya)\n",
    "lines(Cyano_rec$Age, my_prediction$fit, col=\"violet\")\n",
    "\n",
    "# plot 95% confidence interval\n",
    "lines(Cyano_rec$Age,my_prediction$fit + 1.96*my_prediction$se.fit,col=\"violet\",lty=2)\n",
    "lines(Cyano_rec$Age,my_prediction$fit - 1.96*my_prediction$se.fit,col=\"violet\",lty=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even for the trend, we can see where it is significantly different from zero. We take the following functions for granted:\n",
    "\n",
    "[ https://www.fromthebottomoftheheap.net/2014/05/15/identifying-periods-of-change-with-gams/ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "## Functions for derivatives of GAM(M) models ##\n",
    "################################################\n",
    "Deriv <- function(mod, n = 200, eps = 1e-7, newdata, term) {\n",
    "    if(inherits(mod, \"gamm\"))\n",
    "        mod <- mod$gam\n",
    "    m.terms <- attr(terms(mod), \"term.labels\")\n",
    "    if(missing(newdata)) {\n",
    "        newD <- sapply(model.frame(mod)[, m.terms, drop = FALSE],\n",
    "                       function(x) seq(min(x), max(x), length = n))\n",
    "        names(newD) <- m.terms\n",
    "    } else {\n",
    "        newD <- newdata\n",
    "    }\n",
    "    newDF <- data.frame(newD) ## needs to be a data frame for predict\n",
    "    X0 <- predict(mod, newDF, type = \"lpmatrix\")\n",
    "    newDF <- newDF + eps\n",
    "    X1 <- predict(mod, newDF, type = \"lpmatrix\")\n",
    "    Xp <- (X1 - X0) / eps\n",
    "    Xp.r <- NROW(Xp)\n",
    "    Xp.c <- NCOL(Xp)\n",
    "    ## dims of bs\n",
    "    bs.dims <- sapply(mod$smooth, \"[[\", \"bs.dim\") - 1\n",
    "    ## number of smooth terms\n",
    "    t.labs <- attr(mod$terms, \"term.labels\")\n",
    "    ## match the term with the the terms in the model\n",
    "    if(!missing(term)) {\n",
    "        want <- grep(term, t.labs)\n",
    "        if(!identical(length(want), length(term)))\n",
    "            stop(\"One or more 'term's not found in model!\")\n",
    "        t.labs <- t.labs[want]\n",
    "    }\n",
    "    nt <- length(t.labs)\n",
    "    ## list to hold the derivatives\n",
    "    lD <- vector(mode = \"list\", length = nt)\n",
    "    names(lD) <- t.labs\n",
    "    for(i in seq_len(nt)) {\n",
    "        Xi <- Xp * 0\n",
    "        want <- grep(t.labs[i], colnames(X1))\n",
    "        Xi[, want] <- Xp[, want]\n",
    "        df <- Xi %*% coef(mod)\n",
    "        df.sd <- rowSums(Xi %*% mod$Vp * Xi)^.5\n",
    "        lD[[i]] <- list(deriv = df, se.deriv = df.sd)\n",
    "    }\n",
    "    class(lD) <- \"Deriv\"\n",
    "    lD$gamModel <- mod\n",
    "    lD$eps <- eps\n",
    "    lD$eval <- newD - eps\n",
    "    lD ##return\n",
    "}\n",
    "                \n",
    "# return those points where the derivative is 95% significant                       \n",
    "signif_deriv = function(my_gamm,term,other_terms=NULL) {\n",
    "    my_deriv = Deriv(my_gamm)\n",
    "    deriv_is_significant = abs(my_deriv[[term]]$deriv)>1.96*abs(my_deriv[[term]]$se.deriv)\n",
    "    x_values = data.frame(V1 = my_deriv$eval)\n",
    "    colnames(x_values)=term\n",
    "    if (!is.null(other_terms)) {\n",
    "        for (other_term in other_terms) {\n",
    "            x_values[,other_term]=0\n",
    "        }\n",
    "    }\n",
    "    y_values = predict.gam(my_gamm$gam,newdata=x_values,type=\"terms\")[,paste0(\"s(\",term,\")\")]\n",
    "    y_values[!deriv_is_significant]=NA\n",
    "    y_values = y_values + my_gamm$gam$coefficients[1]\n",
    "    return(data.frame(x=x_values[,term],y=y_values))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us calculate the points where the derivative is significantly different from zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate these points\n",
    "significant_derivative_points = signif_deriv(my_gamm,\"Age\")\n",
    "# plot points and model estimate\n",
    "plot(Cyano_rec$Age, Cyano_rec$Cya)\n",
    "lines(Cyano_rec$Age, my_prediction$fit, col=\"violet\")\n",
    "lines(Cyano_rec$Age,my_prediction$fit + 1.96*my_prediction$se.fit,col=\"violet\",lty=2)\n",
    "lines(Cyano_rec$Age,my_prediction$fit - 1.96*my_prediction$se.fit,col=\"violet\",lty=2)\n",
    "# plot a thicker line (line width = 2) to show where the trend is significant\n",
    "lines(significant_derivative_points,col=\"violet\",lwd=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?gamm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model suggests two distinct increases of the cyanobacteria biomarker: \n",
    "* between 1880 and 1940\n",
    "* between 1970 and now\n",
    "\n",
    "But only in 1980-2015, the model has a 95% confidence that there was a systematic increasing trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Observed surface temperature at station BY31\n",
    "\n",
    "The ICES database contains observation data for Landsort Deep SST from the 19th century on. Can we find out if there is a long-term trend?\n",
    "\n",
    "Let us first load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icesdata = read.csv(\"../Data/sst_by31.csv\",sep=\";\")\n",
    "head(icesdata)\n",
    "plot(icesdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to do a GAMM analysis as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ices_gamm = gamm(temperature ~ s(decimalyear, bs=\"cr\", k = 8) , data=icesdata, \n",
    "                 knots=list(decimalyear=x_values), optimMethod=\"ML\")\n",
    "plot(icesdata$decimalyear, icesdata$temperature)\n",
    "lines(icesdata$decimalyear, predict(ices_gamm$gam), col=\"violet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks weird: Do we really see a cooling here?\n",
    "\n",
    "These data are irregular and have a pronounced seasonal cycle.\n",
    "\n",
    "You may find a **seasonal observation bias**: \n",
    "Assume you find a long-term trend - is that \n",
    "* because it is actually getting warmer, or\n",
    "* because you measured more often in summer?\n",
    "\n",
    "Let's add a column **season** to the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the year\n",
    "icesdata$year = floor(icesdata$decimalyear)\n",
    "# subtract it from decimalyear to get the season\n",
    "icesdata$season = icesdata$decimalyear - icesdata$year\n",
    "\n",
    "head(icesdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now fit a statistical model like this:\n",
    "$$ temperature = \\beta_0 + s_1(decimalyear) + s_2(season) + \\varepsilon $$\n",
    "\n",
    "which explicitly contains seasonality.\n",
    "\n",
    "This idea follows this online tutorial:\n",
    "[ https://www.fromthebottomoftheheap.net/2014/05/09/modelling-seasonal-data-with-gam/ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ices_gamm = gamm(temperature ~ s(decimalyear, bs=\"cr\", k = 8) + s(season, bs=\"cc\",k=12), data=icesdata, \n",
    "                 knots=list(decimalyear=x_values, season=c(0,1)), optimMethod=\"ML\", \n",
    "                 correlation = corCAR1(form = ~ decimalyear|year))\n",
    "plot(ices_gamm$gam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to plot the temperature trend together with the data. To do so, we have to make a prediction term by term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ices_gamm$gam$coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the intercept - it is the first of the coefficients\n",
    "intercept = ices_gamm$gam$coefficients[1]\n",
    "intercept\n",
    "\n",
    "# predict the terms one by one\n",
    "my_prediction = predict(ices_gamm$gam,se.fit=TRUE,type=\"terms\")\n",
    "print(my_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the temperature from the first columm\n",
    "pred_temperature = intercept + my_prediction$fit[,1]\n",
    "\n",
    "# get minimum and maximum temperature\n",
    "pred_temperature_min = intercept + my_prediction$fit[,1] - 1.96*my_prediction$se.fit[,1]\n",
    "pred_temperature_max = intercept + my_prediction$fit[,1] + 1.96*my_prediction$se.fit[,1]\n",
    "\n",
    "# do the plot\n",
    "plot(icesdata$decimalyear, icesdata$temperature)\n",
    "lines(icesdata$decimalyear, pred_temperature, col=\"red\")\n",
    "lines(icesdata$decimalyear, pred_temperature_min, lty=2, col=\"red\")\n",
    "lines(icesdata$decimalyear, pred_temperature_max, lty=2, col=\"red\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where is the trend significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_derivative_points = signif_deriv(ices_gamm,term=\"decimalyear\",other_terms = c(\"season\"))\n",
    "plot(icesdata$decimalyear, icesdata$temperature)\n",
    "lines(icesdata$decimalyear, pred_temperature, col=\"red\")\n",
    "lines(icesdata$decimalyear, pred_temperature_min, lty=2, col=\"red\")\n",
    "lines(icesdata$decimalyear, pred_temperature_max, lty=2, col=\"red\")\n",
    "lines(significant_derivative_points, lwd=2, col=\"blue\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
